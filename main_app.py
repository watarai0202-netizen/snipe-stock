import streamlit as st
import pandas as pd
import yfinance as yf
import requests
import base64
import json
from io import BytesIO
import re
from datetime import datetime
import urllib.request

# =========================
# 1. åŸºæœ¬è¨­å®š & èªè¨¼ (Secretsé€£æº)
# =========================
st.set_page_config(page_title="Pre-Market Sniper V5.3", layout="wide")

# ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã¨ãƒˆãƒ¼ã‚¯ãƒ³ã‚’Secretsã‹ã‚‰å–å¾—
MY_PASSWORD = st.secrets["MY_APP_PASSWORD"]
GITHUB_TOKEN = st.secrets["GITHUB_TOKEN"]

if "auth" not in st.session_state: st.session_state.auth = False
if "margin_df" not in st.session_state: st.session_state.margin_df = None
if "candidates_df" not in st.session_state: st.session_state.candidates_df = pd.DataFrame()
if "price_cache" not in st.session_state: st.session_state.price_cache = {}

if not st.session_state.auth:
    st.title("ğŸ”’ èªè¨¼")
    pwd = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
    if pwd == MY_PASSWORD:
        st.session_state.auth = True
        st.rerun()
    st.stop()

# =========================
# 2. GitHub API è¨­å®š
# =========================
# â˜…ã”è‡ªèº«ã®ãƒªãƒã‚¸ãƒˆãƒªåã«å¤‰æ›´ã—ã¦ãã ã•ã„
REPO = "watarai0202-netizen/snipe-stock" 
FILE_PATH = "data/margin_data.csv"
API_URL = f"https://api.github.com/repos/{REPO}/contents/{FILE_PATH}"

def load_from_github():
    """GitHubã‹ã‚‰ä¸€åº¦ã ã‘ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    headers = {"Authorization": f"token {GITHUB_TOKEN}"}
    res = requests.get(API_URL, headers=headers)
    if res.status_code == 200:
        content = base64.b64decode(res.json()["content"]).decode('utf-8')
        return pd.read_csv(BytesIO(content.encode('utf-8')))
    return pd.DataFrame(columns=["ã‚³ãƒ¼ãƒ‰", "ä¿¡ç”¨è²·å¢—", "ä¿¡ç”¨å£²å¢—", "ç¾ç‰©å·®", "æ›´æ–°æ—¥"])

def save_to_github(df):
    """GitHubã¸ä¸€æ‹¬ä¿å­˜ã™ã‚‹"""
    headers = {"Authorization": f"token {GITHUB_TOKEN}"}
    res = requests.get(API_URL, headers=headers)
    sha = res.json()["sha"] if res.status_code == 200 else None
    csv_content = df.to_csv(index=False)
    encoded = base64.b64encode(csv_content.encode('utf-8')).decode('utf-8')
    data = {"message": f"Update {datetime.now()}", "content": encoded, "sha": sha}
    return requests.put(API_URL, headers=headers, data=json.dumps(data)).status_code in [200, 201]

# =========================
# 3. å„ç¨®ã‚¨ãƒ³ã‚¸ãƒ³ã®å®šç¾©
# =========================
def parse_matsui(text):
    """æ¾äº•è¨¼åˆ¸ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è§£æã—ã¦æ•°å€¤ã‚’æŠ½å‡º"""
    try:
        num = lambda s: int(re.sub(r'[^\d]', '', s))
        res = {"ç¾ç‰©": 0, "è²·æ®‹": 0, "å£²æ®‹": 0}
        p = re.search(r'([\d,]+)æ ª\s*(è²·è¶Šã—|å£²è¶Šã—)', text)
        if p: res["ç¾ç‰©"] = num(p.group(1)) * (1 if "è²·è¶Šã—" in p.group(2) else -1)
        b = re.search(r'([\d,]+)æ ª\s*(è²·æ®‹å¢—|è²·æ®‹æ¸›)', text)
        if b: res["è²·æ®‹"] = num(b.group(1)) * (1 if "è²·æ®‹å¢—" in b.group(2) else -1)
        s = re.search(r'([\d,]+)æ ª\s*(å£²æ®‹å¢—|å£²æ®‹æ¸›|å£²æ®‹)', text)
        if s: res["å£²æ®‹"] = num(s.group(1)) * (-1 if "å£²æ®‹æ¸›" in s.group(2) else 1)
        return res
    except: return None

# =========================
# 4. ãƒ¡ã‚¤ãƒ³ UI
# =========================
st.title("ğŸ¯ Pre-Market Sniper V5.3")

# èµ·å‹•æ™‚ã«GitHubã‹ã‚‰ãƒ­ãƒ¼ãƒ‰
if st.session_state.margin_df is None:
    st.session_state.margin_df = load_from_github()

# --- Step 1: ã‚¹ã‚­ãƒ£ãƒ³ ---
st.sidebar.subheader("ğŸ” Step 1: ã‚¹ã‚­ãƒ£ãƒ³")
market = st.sidebar.radio("å¸‚å ´", ("ãƒ—ãƒ©ã‚¤ãƒ ", "ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰", "ã‚°ãƒ­ãƒ¼ã‚¹"))
min_val = st.sidebar.slider("æœ€ä½å£²è²·ä»£é‡‘(å„„)", 1, 50, 10)
if st.sidebar.button("ã‚¹ã‚­ãƒ£ãƒ³é–‹å§‹", type="primary"):
    with st.spinner("ä¸€æ‹¬ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­..."):
        master_url = "https://raw.githubusercontent.com/watarai0202-netizen/stocktest-app-1/main/data_j.csv"
        with urllib.request.urlopen(master_url) as resp:
            master = pd.read_csv(BytesIO(resp.read()))
        m_key = f"{market}ï¼ˆå†…å›½æ ªå¼ï¼‰"
        tickers = [f"{str(c).strip().replace('.0','')}.T" for c in master[master["å¸‚å ´ãƒ»å•†å“åŒºåˆ†"] == m_key]["ã‚³ãƒ¼ãƒ‰"]]
        
        found = []
        batch_size = 100
        for i in range(0, len(tickers), batch_size):
            batch = tickers[i:i+batch_size]
            df_p = yf.download(batch, period="1mo", interval="1d", group_by="ticker", progress=False)
            for t in batch:
                try:
                    data = df_p[t].dropna()
                    if len(data) < 15: continue
                    vol_y = data["Volume"].iloc[-1]
                    avg_vol = data["Volume"].iloc[-6:-1].mean()
                    rvol = vol_y / avg_vol
                    close_y = data["Close"].iloc[-1]
                    # RVOL & 10æ—¥é«˜å€¤ãƒ–ãƒ¬ã‚¤ã‚¯ & ä»£é‡‘æ¡ä»¶
                    if 1.15 <= rvol <= 1.6 and close_y >= data["High"].iloc[-11:-1].max() and (close_y * vol_y / 1e8) >= min_val:
                        found.append({"ã‚³ãƒ¼ãƒ‰": int(t.replace(".T", "")), "rvol": rvol})
                        # 5MAã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
                        st.session_state.price_cache[int(t.replace(".T", ""))] = data["Close"].tail(5).mean()
                except: continue
        
        # RVOLé †ã«ä¸Šä½10éŠ˜æŸ„ã‚’æŠ½å‡º
        sorted_f = sorted(found, key=lambda x: x["rvol"], reverse=True)[:10]
        st.session_state.candidates_df = pd.DataFrame(sorted_f)
        st.success("ã‚¹ã‚­ãƒ£ãƒ³å®Œäº†")

# --- Step 2: éœ€çµ¦å…¥åŠ› ---
st.subheader("ğŸ“ Step 2: éœ€çµ¦å…¥åŠ›")
if not st.session_state.candidates_df.empty:
    # å€™è£œã¨æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®çµåˆ
    display_df = pd.merge(st.session_state.candidates_df[["ã‚³ãƒ¼ãƒ‰"]], 
                          st.session_state.margin_df, on="ã‚³ãƒ¼ãƒ‰", how="left").fillna(0)
    
    col1, col2 = st.columns([1, 2])
    with col1:
        t_code = st.selectbox("éŠ˜æŸ„é¸æŠ", display_df["ã‚³ãƒ¼ãƒ‰"])
        p_text = st.text_area("æ¾äº•ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒšãƒ¼ã‚¹ãƒˆ", height=100)
        if st.button("è¡¨ã«åæ˜ "):
            parsed = parse_matsui(p_text)
            if parsed:
                # ãƒ¡ãƒ¢ãƒªä¸Šã®ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
                st.session_state.margin_df = st.session_state.margin_df[st.session_state.margin_df["ã‚³ãƒ¼ãƒ‰"] != int(t_code)]
                new_row = pd.DataFrame([{
                    "ã‚³ãƒ¼ãƒ‰": int(t_code), "ä¿¡ç”¨è²·å¢—": parsed["è²·æ®‹"], "ä¿¡ç”¨å£²å¢—": parsed["å£²æ®‹"], 
                    "ç¾ç‰©å·®": parsed["ç¾ç‰©"], "æ›´æ–°æ—¥": datetime.now().strftime("%Y-%m-%d")
                }])
                st.session_state.margin_df = pd.concat([st.session_state.margin_df, new_row])
                if "editor" in st.session_state: del st.session_state["editor"]
                st.rerun()
    
    with col2:
        edited_df = st.data_editor(display_df, use_container_width=True, key="editor")
    
    if st.button("ğŸ’¾ å…¨å…¥åŠ›ã‚’GitHubã¸ä¿å­˜"):
        with st.spinner("åŒæœŸä¸­..."):
            if save_to_github(st.session_state.margin_df):
                st.success("GitHubã®ä¿å­˜ã«æˆåŠŸã—ã¾ã—ãŸï¼")

# --- Step 3: æŒ‡å€¤ç®—å‡º ---
if st.button("ğŸš€ Step 3: æŒ‡å€¤ç®—å‡º"):
    if edited_df.empty:
        st.warning("å€™è£œãŒã‚ã‚Šã¾ã›ã‚“")
    else:
        # å…ˆç‰©å–å¾— (8:30æ™‚ç‚¹ã®èª¿æ•´ç”¨)
        df_f = yf.download("NIY=F", period="1d", interval="5m", progress=False)
        f_rate = (df_f['Close'].iloc[-1] - df_f['Low'].min()) / (df_f['High'].max() - df_f['Low'].min())
        f_adj = 1.0 if f_rate >= 0.6 else 0.985 if f_rate <= 0.3 else 0.995
        
        res = []
        for _, row in edited_df.iterrows():
            code = int(row['ã‚³ãƒ¼ãƒ‰'])
            ma5 = st.session_state.price_cache.get(code, 0)
            # éœ€çµ¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
            score = (15 if row['ä¿¡ç”¨å£²å¢—'] > row['ä¿¡ç”¨è²·å¢—'] else 0) + (5 if row['ç¾ç‰©å·®'] > 0 else 0) - (15 if row['ä¿¡ç”¨è²·å¢—'] > 50000 else 0)
            res.append({
                "ã‚³ãƒ¼ãƒ‰": code, "5MA": f"{ma5:,.0f}", "éœ€çµ¦ã‚¹ã‚³ã‚¢": score, 
                "ç†æƒ³æŒ‡å€¤": f"{ma5 * f_adj:,.0f}", "åˆ¤å®š": "ğŸ¯ç‹™æ’ƒ" if score >= 15 else "æ…é‡"
            })
        st.table(pd.DataFrame(res))
